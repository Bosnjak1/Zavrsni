{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5107057",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs awailable:  1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, BatchNormalization, Activation\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.constraints import maxnorm\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import regularizers, optimizers\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras import backend as K \n",
    "K.set_image_data_format('channels_last')\n",
    "from keras.datasets import cifar10\n",
    "print(\"Num GPUs awailable: \", len(tf.config.experimental.list_physical_devices(\"GPU\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3013a3bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                20490     \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 309,290\n",
      "Trainable params: 308,394\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "mean = np.mean(X_train,axis=(0,1,2,3))\n",
    "std = np.std(X_train,axis=(0,1,2,3))\n",
    "x_train = (X_train-mean)/(std+1e-7)\n",
    "x_test = (X_test-mean)/(std+1e-7)\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train, 10)\n",
    "y_test = np_utils.to_categorical(y_test, 10)\n",
    "\n",
    "weight_decay = 1e-4\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), input_shape=X_train.shape[1:], padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), padding='same', kernel_regularizer=regularizers.l2(weight_decay))) \n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(64, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(64, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv2D(128, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(128, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Flatten()) \n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "872887ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,\n",
    "    samplewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    "    samplewise_std_normalization=False,\n",
    "    zca_whitening=False,\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False\n",
    "    )\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d63ad792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 1.8861 - accuracy: 0.4256 - val_loss: 1.6351 - val_accuracy: 0.5364\n",
      "Epoch 2/250\n",
      "781/781 [==============================] - 39s 49ms/step - loss: 1.2584 - accuracy: 0.5912 - val_loss: 1.0999 - val_accuracy: 0.6601\n",
      "Epoch 3/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 1.0712 - accuracy: 0.6546 - val_loss: 1.0132 - val_accuracy: 0.6954\n",
      "Epoch 4/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.9646 - accuracy: 0.6933 - val_loss: 0.9700 - val_accuracy: 0.7099\n",
      "Epoch 5/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.9033 - accuracy: 0.7175 - val_loss: 0.7923 - val_accuracy: 0.7677\n",
      "Epoch 6/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.8552 - accuracy: 0.7358 - val_loss: 0.7812 - val_accuracy: 0.7693\n",
      "Epoch 7/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.8218 - accuracy: 0.7499 - val_loss: 0.7986 - val_accuracy: 0.7768\n",
      "Epoch 8/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.7915 - accuracy: 0.7621 - val_loss: 0.8095 - val_accuracy: 0.7705\n",
      "Epoch 9/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.7670 - accuracy: 0.7739 - val_loss: 0.7044 - val_accuracy: 0.8009\n",
      "Epoch 10/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.7470 - accuracy: 0.7802 - val_loss: 0.7078 - val_accuracy: 0.7986\n",
      "Epoch 11/250\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.7324 - accuracy: 0.7871 - val_loss: 0.7052 - val_accuracy: 0.8072\n",
      "Epoch 12/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.7254 - accuracy: 0.7897 - val_loss: 0.6671 - val_accuracy: 0.8177\n",
      "Epoch 13/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.7116 - accuracy: 0.7974 - val_loss: 0.6947 - val_accuracy: 0.8016\n",
      "Epoch 14/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.7008 - accuracy: 0.8021 - val_loss: 0.6578 - val_accuracy: 0.8227\n",
      "Epoch 15/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.6946 - accuracy: 0.8052 - val_loss: 0.7200 - val_accuracy: 0.8007\n",
      "Epoch 16/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.6880 - accuracy: 0.8069 - val_loss: 0.7552 - val_accuracy: 0.7942\n",
      "Epoch 17/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.6775 - accuracy: 0.8127 - val_loss: 0.6535 - val_accuracy: 0.8200\n",
      "Epoch 18/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.6706 - accuracy: 0.8135 - val_loss: 0.6990 - val_accuracy: 0.8104\n",
      "Epoch 19/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.6674 - accuracy: 0.8163 - val_loss: 0.5903 - val_accuracy: 0.8421\n",
      "Epoch 20/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.6594 - accuracy: 0.8194 - val_loss: 0.6754 - val_accuracy: 0.8176\n",
      "Epoch 21/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.6549 - accuracy: 0.8215 - val_loss: 0.6058 - val_accuracy: 0.8438\n",
      "Epoch 22/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.6574 - accuracy: 0.8199 - val_loss: 0.6465 - val_accuracy: 0.8319\n",
      "Epoch 23/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.6487 - accuracy: 0.8245 - val_loss: 0.6268 - val_accuracy: 0.8330\n",
      "Epoch 24/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.6487 - accuracy: 0.8263 - val_loss: 0.6088 - val_accuracy: 0.8406\n",
      "Epoch 25/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.6385 - accuracy: 0.8271 - val_loss: 0.6226 - val_accuracy: 0.8377\n",
      "Epoch 26/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.6371 - accuracy: 0.8288 - val_loss: 0.6417 - val_accuracy: 0.8315\n",
      "Epoch 27/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.6317 - accuracy: 0.8313 - val_loss: 0.6132 - val_accuracy: 0.8382\n",
      "Epoch 28/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.6373 - accuracy: 0.8288 - val_loss: 0.6680 - val_accuracy: 0.8263\n",
      "Epoch 29/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.6278 - accuracy: 0.8350 - val_loss: 0.6649 - val_accuracy: 0.8303\n",
      "Epoch 30/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.6298 - accuracy: 0.8321 - val_loss: 0.5968 - val_accuracy: 0.8503\n",
      "Epoch 31/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.6270 - accuracy: 0.8334 - val_loss: 0.6208 - val_accuracy: 0.8400\n",
      "Epoch 32/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.6277 - accuracy: 0.8342 - val_loss: 0.6306 - val_accuracy: 0.8388\n",
      "Epoch 33/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.6213 - accuracy: 0.8353 - val_loss: 0.6330 - val_accuracy: 0.8354\n",
      "Epoch 34/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.6240 - accuracy: 0.8358 - val_loss: 0.6208 - val_accuracy: 0.8401\n",
      "Epoch 35/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.6147 - accuracy: 0.8380 - val_loss: 0.6079 - val_accuracy: 0.8442\n",
      "Epoch 36/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.6199 - accuracy: 0.8367 - val_loss: 0.6141 - val_accuracy: 0.8440\n",
      "Epoch 37/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.6146 - accuracy: 0.8383 - val_loss: 0.6754 - val_accuracy: 0.8319\n",
      "Epoch 38/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.6136 - accuracy: 0.8408 - val_loss: 0.5823 - val_accuracy: 0.8548\n",
      "Epoch 39/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.6088 - accuracy: 0.8406 - val_loss: 0.6348 - val_accuracy: 0.8372\n",
      "Epoch 40/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.6123 - accuracy: 0.8401 - val_loss: 0.6665 - val_accuracy: 0.8267\n",
      "Epoch 41/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.6080 - accuracy: 0.8399 - val_loss: 0.5999 - val_accuracy: 0.8483\n",
      "Epoch 42/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.6113 - accuracy: 0.8402 - val_loss: 0.5886 - val_accuracy: 0.8535\n",
      "Epoch 43/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.6070 - accuracy: 0.8431 - val_loss: 0.5636 - val_accuracy: 0.8595\n",
      "Epoch 44/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.6036 - accuracy: 0.8441 - val_loss: 0.6165 - val_accuracy: 0.8449\n",
      "Epoch 45/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.6050 - accuracy: 0.8441 - val_loss: 0.5665 - val_accuracy: 0.8633\n",
      "Epoch 46/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.6014 - accuracy: 0.8448 - val_loss: 0.6382 - val_accuracy: 0.8385\n",
      "Epoch 47/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.6050 - accuracy: 0.8439 - val_loss: 0.6428 - val_accuracy: 0.8385\n",
      "Epoch 48/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.5980 - accuracy: 0.8458 - val_loss: 0.6286 - val_accuracy: 0.8434\n",
      "Epoch 49/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.5994 - accuracy: 0.8431 - val_loss: 0.6250 - val_accuracy: 0.8414\n",
      "Epoch 50/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.5993 - accuracy: 0.8454 - val_loss: 0.6141 - val_accuracy: 0.8461\n",
      "Epoch 51/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.5993 - accuracy: 0.8469 - val_loss: 0.5834 - val_accuracy: 0.8537\n",
      "Epoch 52/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.6021 - accuracy: 0.8448 - val_loss: 0.6211 - val_accuracy: 0.8419\n",
      "Epoch 53/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.5970 - accuracy: 0.8469 - val_loss: 0.5616 - val_accuracy: 0.8637\n",
      "Epoch 54/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.5971 - accuracy: 0.8474 - val_loss: 0.5670 - val_accuracy: 0.8597\n",
      "Epoch 55/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.5869 - accuracy: 0.8504 - val_loss: 0.5861 - val_accuracy: 0.8558\n",
      "Epoch 56/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.5945 - accuracy: 0.8481 - val_loss: 0.6022 - val_accuracy: 0.8466\n",
      "Epoch 57/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781/781 [==============================] - 38s 49ms/step - loss: 0.5885 - accuracy: 0.8487 - val_loss: 0.6396 - val_accuracy: 0.8354\n",
      "Epoch 58/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.5926 - accuracy: 0.8472 - val_loss: 0.6013 - val_accuracy: 0.8527\n",
      "Epoch 59/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.5861 - accuracy: 0.8515 - val_loss: 0.5897 - val_accuracy: 0.8550\n",
      "Epoch 60/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.5823 - accuracy: 0.8502 - val_loss: 0.6285 - val_accuracy: 0.8388\n",
      "Epoch 61/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.5893 - accuracy: 0.8491 - val_loss: 0.5629 - val_accuracy: 0.8585\n",
      "Epoch 62/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.5891 - accuracy: 0.8496 - val_loss: 0.6294 - val_accuracy: 0.8442\n",
      "Epoch 63/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.5868 - accuracy: 0.8504 - val_loss: 0.6087 - val_accuracy: 0.8462\n",
      "Epoch 64/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.5834 - accuracy: 0.8517 - val_loss: 0.6194 - val_accuracy: 0.8426\n",
      "Epoch 65/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.5848 - accuracy: 0.8524 - val_loss: 0.5748 - val_accuracy: 0.8611\n",
      "Epoch 66/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.5869 - accuracy: 0.8506 - val_loss: 0.5520 - val_accuracy: 0.8700\n",
      "Epoch 67/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.5780 - accuracy: 0.8526 - val_loss: 0.5918 - val_accuracy: 0.8566\n",
      "Epoch 68/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.5840 - accuracy: 0.8504 - val_loss: 0.6891 - val_accuracy: 0.8301\n",
      "Epoch 69/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.5807 - accuracy: 0.8535 - val_loss: 0.5997 - val_accuracy: 0.8496\n",
      "Epoch 70/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.5792 - accuracy: 0.8544 - val_loss: 0.6332 - val_accuracy: 0.8450\n",
      "Epoch 71/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.5759 - accuracy: 0.8543 - val_loss: 0.5936 - val_accuracy: 0.8490\n",
      "Epoch 72/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.5789 - accuracy: 0.8531 - val_loss: 0.5962 - val_accuracy: 0.8551\n",
      "Epoch 73/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.5793 - accuracy: 0.8531 - val_loss: 0.5594 - val_accuracy: 0.8668\n",
      "Epoch 74/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.5790 - accuracy: 0.8535 - val_loss: 0.5621 - val_accuracy: 0.8640\n",
      "Epoch 75/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.5761 - accuracy: 0.8540 - val_loss: 0.6108 - val_accuracy: 0.8533\n",
      "Epoch 76/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.5763 - accuracy: 0.8543 - val_loss: 0.5884 - val_accuracy: 0.8602\n",
      "Epoch 77/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.5360 - accuracy: 0.8676 - val_loss: 0.5338 - val_accuracy: 0.8701\n",
      "Epoch 78/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.5138 - accuracy: 0.8733 - val_loss: 0.5174 - val_accuracy: 0.8761\n",
      "Epoch 79/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.5061 - accuracy: 0.8749 - val_loss: 0.5338 - val_accuracy: 0.8705\n",
      "Epoch 80/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.5028 - accuracy: 0.8759 - val_loss: 0.4926 - val_accuracy: 0.8806\n",
      "Epoch 81/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.4972 - accuracy: 0.8781 - val_loss: 0.5482 - val_accuracy: 0.8636\n",
      "Epoch 82/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.4971 - accuracy: 0.8745 - val_loss: 0.5285 - val_accuracy: 0.8701\n",
      "Epoch 83/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.4874 - accuracy: 0.8797 - val_loss: 0.5080 - val_accuracy: 0.8770\n",
      "Epoch 84/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.4842 - accuracy: 0.8788 - val_loss: 0.5067 - val_accuracy: 0.8781\n",
      "Epoch 85/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.4782 - accuracy: 0.8790 - val_loss: 0.5490 - val_accuracy: 0.8657\n",
      "Epoch 86/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.4785 - accuracy: 0.8801 - val_loss: 0.5131 - val_accuracy: 0.8718\n",
      "Epoch 87/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.4791 - accuracy: 0.8782 - val_loss: 0.5202 - val_accuracy: 0.8706\n",
      "Epoch 88/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.4764 - accuracy: 0.8800 - val_loss: 0.4978 - val_accuracy: 0.8788\n",
      "Epoch 89/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.4728 - accuracy: 0.8808 - val_loss: 0.5179 - val_accuracy: 0.8717\n",
      "Epoch 90/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.4700 - accuracy: 0.8803 - val_loss: 0.5164 - val_accuracy: 0.8733\n",
      "Epoch 91/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.4748 - accuracy: 0.8785 - val_loss: 0.4790 - val_accuracy: 0.8834\n",
      "Epoch 92/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.4653 - accuracy: 0.8813 - val_loss: 0.5060 - val_accuracy: 0.8755\n",
      "Epoch 93/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.4665 - accuracy: 0.8804 - val_loss: 0.5547 - val_accuracy: 0.8587\n",
      "Epoch 94/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.4606 - accuracy: 0.8831 - val_loss: 0.4961 - val_accuracy: 0.8766\n",
      "Epoch 95/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.4635 - accuracy: 0.8820 - val_loss: 0.5221 - val_accuracy: 0.8674\n",
      "Epoch 96/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.4617 - accuracy: 0.8815 - val_loss: 0.4793 - val_accuracy: 0.8798\n",
      "Epoch 97/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.4571 - accuracy: 0.8831 - val_loss: 0.4714 - val_accuracy: 0.8851\n",
      "Epoch 98/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.4663 - accuracy: 0.8793 - val_loss: 0.5303 - val_accuracy: 0.8682\n",
      "Epoch 99/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.4592 - accuracy: 0.8807 - val_loss: 0.4934 - val_accuracy: 0.8758\n",
      "Epoch 100/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.4556 - accuracy: 0.8810 - val_loss: 0.4791 - val_accuracy: 0.8804\n",
      "Epoch 101/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.4540 - accuracy: 0.8828 - val_loss: 0.5287 - val_accuracy: 0.8672\n",
      "Epoch 102/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.4381 - accuracy: 0.8878 - val_loss: 0.4695 - val_accuracy: 0.8794\n",
      "Epoch 103/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.4293 - accuracy: 0.8908 - val_loss: 0.4753 - val_accuracy: 0.8810\n",
      "Epoch 104/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.4245 - accuracy: 0.8933 - val_loss: 0.4834 - val_accuracy: 0.8810\n",
      "Epoch 105/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.4254 - accuracy: 0.8920 - val_loss: 0.4862 - val_accuracy: 0.8773\n",
      "Epoch 106/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.4222 - accuracy: 0.8924 - val_loss: 0.4929 - val_accuracy: 0.8772\n",
      "Epoch 107/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.4180 - accuracy: 0.8928 - val_loss: 0.4855 - val_accuracy: 0.8768\n",
      "Epoch 108/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.4149 - accuracy: 0.8934 - val_loss: 0.4691 - val_accuracy: 0.8814\n",
      "Epoch 109/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.4142 - accuracy: 0.8942 - val_loss: 0.5068 - val_accuracy: 0.8729\n",
      "Epoch 110/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.4100 - accuracy: 0.8937 - val_loss: 0.4679 - val_accuracy: 0.8851\n",
      "Epoch 111/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.4111 - accuracy: 0.8949 - val_loss: 0.4458 - val_accuracy: 0.8902\n",
      "Epoch 112/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.4103 - accuracy: 0.8940 - val_loss: 0.4648 - val_accuracy: 0.8819\n",
      "Epoch 113/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781/781 [==============================] - 38s 49ms/step - loss: 0.4071 - accuracy: 0.8958 - val_loss: 0.4691 - val_accuracy: 0.8824\n",
      "Epoch 114/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.4066 - accuracy: 0.8935 - val_loss: 0.4763 - val_accuracy: 0.8788\n",
      "Epoch 115/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.4065 - accuracy: 0.8951 - val_loss: 0.4638 - val_accuracy: 0.8789\n",
      "Epoch 116/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.4069 - accuracy: 0.8942 - val_loss: 0.4414 - val_accuracy: 0.8896\n",
      "Epoch 117/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.4036 - accuracy: 0.8966 - val_loss: 0.4317 - val_accuracy: 0.8925\n",
      "Epoch 118/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.4033 - accuracy: 0.8961 - val_loss: 0.4843 - val_accuracy: 0.8755\n",
      "Epoch 119/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.4009 - accuracy: 0.8954 - val_loss: 0.4790 - val_accuracy: 0.8789\n",
      "Epoch 120/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.4014 - accuracy: 0.8964 - val_loss: 0.4874 - val_accuracy: 0.8790\n",
      "Epoch 121/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.4000 - accuracy: 0.8953 - val_loss: 0.4648 - val_accuracy: 0.8829\n",
      "Epoch 122/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.3960 - accuracy: 0.8965 - val_loss: 0.4557 - val_accuracy: 0.8838\n",
      "Epoch 123/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.3986 - accuracy: 0.8965 - val_loss: 0.4388 - val_accuracy: 0.8880\n",
      "Epoch 124/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.3945 - accuracy: 0.8971 - val_loss: 0.4562 - val_accuracy: 0.8856\n",
      "Epoch 125/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.3930 - accuracy: 0.8977 - val_loss: 0.4751 - val_accuracy: 0.8784\n",
      "Epoch 126/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.3977 - accuracy: 0.8962 - val_loss: 0.4666 - val_accuracy: 0.8805\n",
      "Epoch 127/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.3851 - accuracy: 0.8996 - val_loss: 0.4343 - val_accuracy: 0.8873\n",
      "Epoch 128/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.3792 - accuracy: 0.9017 - val_loss: 0.4544 - val_accuracy: 0.8830\n",
      "Epoch 129/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.3808 - accuracy: 0.9015 - val_loss: 0.4492 - val_accuracy: 0.8875\n",
      "Epoch 130/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.3767 - accuracy: 0.9027 - val_loss: 0.4522 - val_accuracy: 0.8861\n",
      "Epoch 131/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.3688 - accuracy: 0.9049 - val_loss: 0.4061 - val_accuracy: 0.8977\n",
      "Epoch 132/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.3742 - accuracy: 0.9020 - val_loss: 0.4653 - val_accuracy: 0.8819\n",
      "Epoch 133/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.3675 - accuracy: 0.9047 - val_loss: 0.4339 - val_accuracy: 0.8917\n",
      "Epoch 134/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.3735 - accuracy: 0.9021 - val_loss: 0.4262 - val_accuracy: 0.8923\n",
      "Epoch 135/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.3693 - accuracy: 0.9057 - val_loss: 0.4450 - val_accuracy: 0.8874\n",
      "Epoch 136/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.3639 - accuracy: 0.9062 - val_loss: 0.4562 - val_accuracy: 0.8840\n",
      "Epoch 137/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.3687 - accuracy: 0.9030 - val_loss: 0.4307 - val_accuracy: 0.8874\n",
      "Epoch 138/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.3680 - accuracy: 0.9042 - val_loss: 0.4650 - val_accuracy: 0.8789\n",
      "Epoch 139/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.3616 - accuracy: 0.9053 - val_loss: 0.4507 - val_accuracy: 0.8859\n",
      "Epoch 140/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.3699 - accuracy: 0.9032 - val_loss: 0.4424 - val_accuracy: 0.8861\n",
      "Epoch 141/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.3644 - accuracy: 0.9040 - val_loss: 0.4450 - val_accuracy: 0.8867\n",
      "Epoch 142/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.3643 - accuracy: 0.9047 - val_loss: 0.4615 - val_accuracy: 0.8836\n",
      "Epoch 143/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.3629 - accuracy: 0.9043 - val_loss: 0.4580 - val_accuracy: 0.8835\n",
      "Epoch 144/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.3631 - accuracy: 0.9045 - val_loss: 0.4332 - val_accuracy: 0.8906\n",
      "Epoch 145/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.3555 - accuracy: 0.9073 - val_loss: 0.4347 - val_accuracy: 0.8856\n",
      "Epoch 146/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.3601 - accuracy: 0.9043 - val_loss: 0.4300 - val_accuracy: 0.8889\n",
      "Epoch 147/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.3625 - accuracy: 0.9036 - val_loss: 0.4308 - val_accuracy: 0.8897\n",
      "Epoch 148/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.3557 - accuracy: 0.9065 - val_loss: 0.4450 - val_accuracy: 0.8869\n",
      "Epoch 149/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.3608 - accuracy: 0.9056 - val_loss: 0.4274 - val_accuracy: 0.8892\n",
      "Epoch 150/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.3581 - accuracy: 0.9058 - val_loss: 0.4350 - val_accuracy: 0.8858\n",
      "Epoch 151/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.3609 - accuracy: 0.9048 - val_loss: 0.4391 - val_accuracy: 0.8854\n",
      "Epoch 152/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.3471 - accuracy: 0.9099 - val_loss: 0.4241 - val_accuracy: 0.8918\n",
      "Epoch 153/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.3420 - accuracy: 0.9094 - val_loss: 0.4235 - val_accuracy: 0.8894\n",
      "Epoch 154/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.3398 - accuracy: 0.9109 - val_loss: 0.4265 - val_accuracy: 0.8882\n",
      "Epoch 155/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.3427 - accuracy: 0.9128 - val_loss: 0.4234 - val_accuracy: 0.8931\n",
      "Epoch 156/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.3377 - accuracy: 0.9117 - val_loss: 0.4394 - val_accuracy: 0.8890\n",
      "Epoch 157/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.3405 - accuracy: 0.9098 - val_loss: 0.4157 - val_accuracy: 0.8917\n",
      "Epoch 158/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.3316 - accuracy: 0.9126 - val_loss: 0.4433 - val_accuracy: 0.8860\n",
      "Epoch 159/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.3314 - accuracy: 0.9149 - val_loss: 0.4147 - val_accuracy: 0.8958\n",
      "Epoch 160/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.3393 - accuracy: 0.9120 - val_loss: 0.4302 - val_accuracy: 0.8892\n",
      "Epoch 161/250\n",
      "781/781 [==============================] - 39s 49ms/step - loss: 0.3340 - accuracy: 0.9137 - val_loss: 0.4221 - val_accuracy: 0.8911\n",
      "Epoch 162/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.3361 - accuracy: 0.9121 - val_loss: 0.4268 - val_accuracy: 0.8919\n",
      "Epoch 163/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.3304 - accuracy: 0.9146 - val_loss: 0.4184 - val_accuracy: 0.8928\n",
      "Epoch 164/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.3345 - accuracy: 0.9116 - val_loss: 0.4158 - val_accuracy: 0.8942\n",
      "Epoch 165/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.3240 - accuracy: 0.9182 - val_loss: 0.4157 - val_accuracy: 0.8953\n",
      "Epoch 166/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.3314 - accuracy: 0.9142 - val_loss: 0.4346 - val_accuracy: 0.8892\n",
      "Epoch 167/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.3298 - accuracy: 0.9138 - val_loss: 0.4174 - val_accuracy: 0.8926\n",
      "Epoch 168/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781/781 [==============================] - 38s 49ms/step - loss: 0.3297 - accuracy: 0.9134 - val_loss: 0.4314 - val_accuracy: 0.8901\n",
      "Epoch 169/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.3249 - accuracy: 0.9163 - val_loss: 0.4354 - val_accuracy: 0.8868\n",
      "Epoch 170/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.3307 - accuracy: 0.9142 - val_loss: 0.4186 - val_accuracy: 0.8919\n",
      "Epoch 171/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.3281 - accuracy: 0.9142 - val_loss: 0.4145 - val_accuracy: 0.8928\n",
      "Epoch 172/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.3286 - accuracy: 0.9147 - val_loss: 0.4260 - val_accuracy: 0.8917\n",
      "Epoch 173/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.3238 - accuracy: 0.9157 - val_loss: 0.4159 - val_accuracy: 0.8939\n",
      "Epoch 174/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.3248 - accuracy: 0.9143 - val_loss: 0.4212 - val_accuracy: 0.8918\n",
      "Epoch 175/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.3265 - accuracy: 0.9129 - val_loss: 0.4183 - val_accuracy: 0.8914\n",
      "Epoch 176/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.3205 - accuracy: 0.9157 - val_loss: 0.4226 - val_accuracy: 0.8923\n",
      "Epoch 177/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.3163 - accuracy: 0.9163 - val_loss: 0.4235 - val_accuracy: 0.8902\n",
      "Epoch 178/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.3182 - accuracy: 0.9162 - val_loss: 0.4296 - val_accuracy: 0.8884\n",
      "Epoch 179/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.3204 - accuracy: 0.9168 - val_loss: 0.4062 - val_accuracy: 0.8943\n",
      "Epoch 180/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.3162 - accuracy: 0.9165 - val_loss: 0.4120 - val_accuracy: 0.8929\n",
      "Epoch 181/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.3168 - accuracy: 0.9173 - val_loss: 0.4124 - val_accuracy: 0.8918\n",
      "Epoch 182/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.3176 - accuracy: 0.9169 - val_loss: 0.4203 - val_accuracy: 0.8923\n",
      "Epoch 183/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.3155 - accuracy: 0.9165 - val_loss: 0.4313 - val_accuracy: 0.8891\n",
      "Epoch 184/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.3128 - accuracy: 0.9168 - val_loss: 0.4038 - val_accuracy: 0.8954\n",
      "Epoch 185/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.3175 - accuracy: 0.9162 - val_loss: 0.4146 - val_accuracy: 0.8924\n",
      "Epoch 186/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.3098 - accuracy: 0.9193 - val_loss: 0.4147 - val_accuracy: 0.8931\n",
      "Epoch 187/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.3115 - accuracy: 0.9176 - val_loss: 0.4105 - val_accuracy: 0.8955\n",
      "Epoch 188/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.3085 - accuracy: 0.9189 - val_loss: 0.4106 - val_accuracy: 0.8966\n",
      "Epoch 189/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.3095 - accuracy: 0.9203 - val_loss: 0.4191 - val_accuracy: 0.8936\n",
      "Epoch 190/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.3129 - accuracy: 0.9181 - val_loss: 0.4187 - val_accuracy: 0.8921\n",
      "Epoch 191/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.3102 - accuracy: 0.9200 - val_loss: 0.4174 - val_accuracy: 0.8905\n",
      "Epoch 192/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.3115 - accuracy: 0.9176 - val_loss: 0.4194 - val_accuracy: 0.8916\n",
      "Epoch 193/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.3135 - accuracy: 0.9185 - val_loss: 0.4130 - val_accuracy: 0.8922\n",
      "Epoch 194/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.3071 - accuracy: 0.9198 - val_loss: 0.4087 - val_accuracy: 0.8940\n",
      "Epoch 195/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.3089 - accuracy: 0.9201 - val_loss: 0.4035 - val_accuracy: 0.8942\n",
      "Epoch 196/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.3081 - accuracy: 0.9187 - val_loss: 0.4127 - val_accuracy: 0.8928\n",
      "Epoch 197/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.3064 - accuracy: 0.9200 - val_loss: 0.4189 - val_accuracy: 0.8914\n",
      "Epoch 198/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.3021 - accuracy: 0.9207 - val_loss: 0.4114 - val_accuracy: 0.8934\n",
      "Epoch 199/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.3082 - accuracy: 0.9190 - val_loss: 0.4242 - val_accuracy: 0.8905\n",
      "Epoch 200/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.3097 - accuracy: 0.9174 - val_loss: 0.4067 - val_accuracy: 0.8964\n",
      "Epoch 201/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.3043 - accuracy: 0.9215 - val_loss: 0.4242 - val_accuracy: 0.8912\n",
      "Epoch 202/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.3068 - accuracy: 0.9203 - val_loss: 0.4098 - val_accuracy: 0.8942\n",
      "Epoch 203/250\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3053 - accuracy: 0.9194 - val_loss: 0.4148 - val_accuracy: 0.8942\n",
      "Epoch 204/250\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3069 - accuracy: 0.9197 - val_loss: 0.4134 - val_accuracy: 0.8921\n",
      "Epoch 205/250\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3067 - accuracy: 0.9215 - val_loss: 0.4059 - val_accuracy: 0.8946\n",
      "Epoch 206/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.2998 - accuracy: 0.9215 - val_loss: 0.4016 - val_accuracy: 0.8961\n",
      "Epoch 207/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.3022 - accuracy: 0.9206 - val_loss: 0.4134 - val_accuracy: 0.8943\n",
      "Epoch 208/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.3030 - accuracy: 0.9220 - val_loss: 0.4110 - val_accuracy: 0.8943\n",
      "Epoch 209/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.2991 - accuracy: 0.9218 - val_loss: 0.4030 - val_accuracy: 0.8975\n",
      "Epoch 210/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.2993 - accuracy: 0.9229 - val_loss: 0.4058 - val_accuracy: 0.8946\n",
      "Epoch 211/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.2982 - accuracy: 0.9214 - val_loss: 0.4079 - val_accuracy: 0.8944\n",
      "Epoch 212/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.3024 - accuracy: 0.9212 - val_loss: 0.4032 - val_accuracy: 0.8965\n",
      "Epoch 213/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.2973 - accuracy: 0.9221 - val_loss: 0.4071 - val_accuracy: 0.8952\n",
      "Epoch 214/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.3002 - accuracy: 0.9214 - val_loss: 0.4044 - val_accuracy: 0.8972\n",
      "Epoch 215/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.3009 - accuracy: 0.9209 - val_loss: 0.4036 - val_accuracy: 0.8975\n",
      "Epoch 216/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.3027 - accuracy: 0.9193 - val_loss: 0.4022 - val_accuracy: 0.8960\n",
      "Epoch 217/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.3008 - accuracy: 0.9216 - val_loss: 0.3986 - val_accuracy: 0.8979\n",
      "Epoch 218/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.3010 - accuracy: 0.9205 - val_loss: 0.4088 - val_accuracy: 0.8945\n",
      "Epoch 219/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.2955 - accuracy: 0.9226 - val_loss: 0.4077 - val_accuracy: 0.8952\n",
      "Epoch 220/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.2988 - accuracy: 0.9219 - val_loss: 0.4051 - val_accuracy: 0.8971\n",
      "Epoch 221/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.2993 - accuracy: 0.9210 - val_loss: 0.4121 - val_accuracy: 0.8950\n",
      "Epoch 222/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.2992 - accuracy: 0.9199 - val_loss: 0.4009 - val_accuracy: 0.8963\n",
      "Epoch 223/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781/781 [==============================] - 38s 49ms/step - loss: 0.2976 - accuracy: 0.9223 - val_loss: 0.3994 - val_accuracy: 0.8971\n",
      "Epoch 224/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.2979 - accuracy: 0.9212 - val_loss: 0.4025 - val_accuracy: 0.8971\n",
      "Epoch 225/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.2974 - accuracy: 0.9225 - val_loss: 0.3999 - val_accuracy: 0.8969\n",
      "Epoch 226/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.2962 - accuracy: 0.9225 - val_loss: 0.4043 - val_accuracy: 0.8955\n",
      "Epoch 227/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.2953 - accuracy: 0.9208 - val_loss: 0.4083 - val_accuracy: 0.8938\n",
      "Epoch 228/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.2923 - accuracy: 0.9233 - val_loss: 0.4013 - val_accuracy: 0.8968\n",
      "Epoch 229/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.3004 - accuracy: 0.9223 - val_loss: 0.4033 - val_accuracy: 0.8976\n",
      "Epoch 230/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.2967 - accuracy: 0.9216 - val_loss: 0.4004 - val_accuracy: 0.8975\n",
      "Epoch 231/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.2945 - accuracy: 0.9229 - val_loss: 0.4049 - val_accuracy: 0.8964\n",
      "Epoch 232/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.2961 - accuracy: 0.9221 - val_loss: 0.4022 - val_accuracy: 0.8962\n",
      "Epoch 233/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.2932 - accuracy: 0.9237 - val_loss: 0.4026 - val_accuracy: 0.8966\n",
      "Epoch 234/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.2911 - accuracy: 0.9234 - val_loss: 0.4079 - val_accuracy: 0.8946\n",
      "Epoch 235/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.2940 - accuracy: 0.9240 - val_loss: 0.4002 - val_accuracy: 0.8961\n",
      "Epoch 236/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.2924 - accuracy: 0.9232 - val_loss: 0.4074 - val_accuracy: 0.8966\n",
      "Epoch 237/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.2980 - accuracy: 0.9225 - val_loss: 0.4077 - val_accuracy: 0.8958\n",
      "Epoch 238/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.2964 - accuracy: 0.9225 - val_loss: 0.4062 - val_accuracy: 0.8953\n",
      "Epoch 239/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.2903 - accuracy: 0.9243 - val_loss: 0.4050 - val_accuracy: 0.8964\n",
      "Epoch 240/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.2936 - accuracy: 0.9224 - val_loss: 0.4043 - val_accuracy: 0.8960\n",
      "Epoch 241/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.2945 - accuracy: 0.9242 - val_loss: 0.4123 - val_accuracy: 0.8934\n",
      "Epoch 242/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.2933 - accuracy: 0.9239 - val_loss: 0.4084 - val_accuracy: 0.8941\n",
      "Epoch 243/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.2908 - accuracy: 0.9238 - val_loss: 0.4058 - val_accuracy: 0.8951\n",
      "Epoch 244/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.2937 - accuracy: 0.9228 - val_loss: 0.4033 - val_accuracy: 0.8973\n",
      "Epoch 245/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.2944 - accuracy: 0.9220 - val_loss: 0.4061 - val_accuracy: 0.8962\n",
      "Epoch 246/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.2930 - accuracy: 0.9242 - val_loss: 0.4045 - val_accuracy: 0.8952\n",
      "Epoch 247/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.2945 - accuracy: 0.9229 - val_loss: 0.4046 - val_accuracy: 0.8962\n",
      "Epoch 248/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.2921 - accuracy: 0.9242 - val_loss: 0.4096 - val_accuracy: 0.8957\n",
      "Epoch 249/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.2945 - accuracy: 0.9231 - val_loss: 0.4093 - val_accuracy: 0.8953\n",
      "Epoch 250/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.2900 - accuracy: 0.9237 - val_loss: 0.4089 - val_accuracy: 0.8956\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    lrate = 0.001\n",
    "    if epoch > 75:\n",
    "        lrate = 0.0005\n",
    "    if epoch > 100:\n",
    "        lrate = 0.0003\n",
    "    if epoch > 125:\n",
    "        lrate = 0.0002\n",
    "    if epoch > 150:\n",
    "        lrate = 0.0001\n",
    "    if epoch > 175:\n",
    "        lrate = 0.00005\n",
    "    if epoch > 200:\n",
    "        lrate = 0.00003\n",
    "    if epoch > 225:\n",
    "        lrate = 0.00002\n",
    "    return lrate\n",
    "\n",
    "batch_size = 64\n",
    "epochs=250\n",
    " \n",
    "opt_rms = keras.optimizers.rmsprop(lr=0.001,decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "        optimizer=opt_rms,\n",
    "        metrics=['accuracy'])\n",
    "model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),steps_per_epoch=x_train.shape[0] // batch_size,epochs=epochs,verbose=1,validation_data=(x_test,y_test), callbacks=[LearningRateScheduler(lr_schedule)])\n",
    "model.save_weights('cifar10_normal_rms_ep250.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5988e2c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 214us/step\n",
      "\n",
      "Test result: 89.560 loss: 0.409\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(x_test, y_test, batch_size=128, verbose=1)\n",
    "print('\\nTest result: %.3f loss: %.3f' % (scores[1]*100,scores[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d153e68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model \n",
    "model.save('project_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8442526",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model \n",
    "model = load_model('project_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "203b610b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from keras.preprocessing import image\n",
    "\n",
    "test_image1 =image.load_img('brod.jpg',target_size =(32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2c3e73ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00\n",
      "  0.000000e+00 9.205164e-30 0.000000e+00 1.000000e+00 0.000000e+00]]\n",
      "Ship\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x15c168b3648>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_image =image.img_to_array(test_image1) \n",
    "test_image =np.expand_dims(test_image, axis =0) \n",
    "result = model.predict(test_image) \n",
    "print(result) \n",
    "\n",
    "if result[0][0]==1: \n",
    "    print(\"Aeroplane\") \n",
    "elif result[0][1]==1: \n",
    "    print('Automobile') \n",
    "elif result[0][2]==1: \n",
    "    print('Bird') \n",
    "elif result[0][3]==1: \n",
    "    print('Cat') \n",
    "elif result[0][4]==1: \n",
    "    print('Deer') \n",
    "elif result[0][5]==1: \n",
    "    print('Dog') \n",
    "elif result[0][6]==1: \n",
    "    print('Frog') \n",
    "elif result[0][7]==1: \n",
    "    print('Horse') \n",
    "elif result[0][8]==1: \n",
    "    print('Ship') \n",
    "elif result[0][9]==1: \n",
    "    print('Truck') \n",
    "else: \n",
    "    print('Error')\n",
    "    \n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt \n",
    "plt.imshow(test_image1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e225a51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
